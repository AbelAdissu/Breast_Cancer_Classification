{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG6HefuxkeKrxZ44A5/9hy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbelAdissu/Breast_Cancer_Classification/blob/main/Breast_Cancer_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing:\n",
        "\n",
        "In this section, you'll perform various data preprocessing tasks."
      ],
      "metadata": {
        "id": "zCs7-MH36hFL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a42NzPXG6UJ4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "breast_cancer_dataset = sklearn.datasets.load_breast_cancer()\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data_frame = pd.DataFrame(breast_cancer_dataset.data, columns=breast_cancer_dataset.feature_names)\n",
        "\n",
        "# Add the target column\n",
        "data_frame[\"label\"] = breast_cancer_dataset.target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring the Data:\n",
        "\n",
        "In this section, you'll explore the dataset and check for missing values."
      ],
      "metadata": {
        "id": "k8DBAG3J6lAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of rows and columns in the data\n",
        "print(data_frame.shape)\n",
        "\n",
        "# Get information about the data types and missing values\n",
        "data_frame.info()\n",
        "\n",
        "# Check for missing values\n",
        "data_frame.isnull().sum()\n",
        "\n",
        "# Get statistical descriptions of the data\n",
        "data_frame.describe()\n"
      ],
      "metadata": {
        "id": "eHEhVk276kSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Splitting:\n",
        "\n",
        "Split the data into training and testing sets."
      ],
      "metadata": {
        "id": "ZzcV16e06tIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features (X) and labels (Y)\n",
        "X = data_frame.drop(\"label\", axis=1)\n",
        "Y = data_frame[\"label\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n"
      ],
      "metadata": {
        "id": "tcZLM90k6qOK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization:\n",
        "\n",
        "Standardize the features to have zero mean and unit variance."
      ],
      "metadata": {
        "id": "McfI4EuB63Q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "x_train_std = scaler.fit_transform(x_train)\n",
        "x_test_std = scaler.transform(x_test)\n"
      ],
      "metadata": {
        "id": "VyyPIJgk62hh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network Setup and Training:\n",
        "\n",
        "Set up a simple neural network model and train it."
      ],
      "metadata": {
        "id": "4M9T8XcR6-Yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for TensorFlow\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "# Define the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(30,)),\n",
        "    keras.layers.Dense(20, activation=\"relu\"),\n",
        "    keras.layers.Dense(2, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train_std, y_train, validation_split=0.1, epochs=10)\n"
      ],
      "metadata": {
        "id": "0cG7odja69mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Training History:\n",
        "\n",
        "Visualize the training and validation accuracy and loss."
      ],
      "metadata": {
        "id": "vcbrVF3O7E3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training and validation accuracy\n",
        "training_accuracy = history.history[\"accuracy\"]\n",
        "validation_accuracy = history.history[\"val_accuracy\"]\n",
        "epochs = range(1, len(training_accuracy) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, training_accuracy, label=\"Training Accuracy\", marker='o')\n",
        "plt.plot(epochs, validation_accuracy, label=\"Validation Accuracy\", marker='o')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Visualize training and validation loss\n",
        "training_loss = history.history[\"loss\"]\n",
        "validation_loss = history.history[\"val_loss\"]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, training_loss, label=\"Training Loss\", marker='o')\n",
        "plt.plot(epochs, validation_loss, label=\"Validation Loss\", marker='o')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4o1SFEnY7D5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation and Predictions:\n",
        "\n",
        "Evaluate the model on the test set and make predictions."
      ],
      "metadata": {
        "id": "xaxxEq0i7Kqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(x_test_std, y_test)\n",
        "print(accuracy)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(x_test_std)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = [np.argmax(i) for i in y_pred]\n",
        "print(y_pred_labels)\n"
      ],
      "metadata": {
        "id": "-ytvjiPc7Ja2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This completes your code for training a neural network to classify breast cancer tumors. The model is trained, evaluated, and used to make predictions on the test data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "585JV4qP7Rzt"
      }
    }
  ]
}